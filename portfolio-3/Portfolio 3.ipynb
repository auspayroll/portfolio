{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predicting the Genre of Books from Summaries\n",
    "\n",
    "The goal is to correctly classify books into one of 5 genres using the meta data provided. \n",
    "\n",
    "We'll use a set of book summaries from the [CMU Book Summaries Corpus](http://www.cs.cmu.edu/~dbamman/booksummaries.html) in this experiment.  This contains a large number of summaries (16,559) and includes meta-data about the genre of the books taken from Freebase.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preparation\n",
    "\n",
    "The first task is to read the data. It is made available in tab-separated format but has no column headings. The names come from the [ReadMe](data/booksummaries/README.txt) file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>wid</th>\n",
       "      <th>fid</th>\n",
       "      <th>title</th>\n",
       "      <th>author</th>\n",
       "      <th>date</th>\n",
       "      <th>genres</th>\n",
       "      <th>summary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>620</td>\n",
       "      <td>/m/0hhy</td>\n",
       "      <td>Animal Farm</td>\n",
       "      <td>George Orwell</td>\n",
       "      <td>1945-08-17</td>\n",
       "      <td>{\"/m/016lj8\": \"Roman \\u00e0 clef\", \"/m/06nbt\":...</td>\n",
       "      <td>Old Major, the old boar on the Manor Farm, ca...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>843</td>\n",
       "      <td>/m/0k36</td>\n",
       "      <td>A Clockwork Orange</td>\n",
       "      <td>Anthony Burgess</td>\n",
       "      <td>1962</td>\n",
       "      <td>{\"/m/06n90\": \"Science Fiction\", \"/m/0l67h\": \"N...</td>\n",
       "      <td>Alex, a teenager living in near-future Englan...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>986</td>\n",
       "      <td>/m/0ldx</td>\n",
       "      <td>The Plague</td>\n",
       "      <td>Albert Camus</td>\n",
       "      <td>1947</td>\n",
       "      <td>{\"/m/02m4t\": \"Existentialism\", \"/m/02xlf\": \"Fi...</td>\n",
       "      <td>The text of The Plague is divided into five p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1756</td>\n",
       "      <td>/m/0sww</td>\n",
       "      <td>An Enquiry Concerning Human Understanding</td>\n",
       "      <td>David Hume</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>The argument of the Enquiry proceeds by a ser...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2080</td>\n",
       "      <td>/m/0wkt</td>\n",
       "      <td>A Fire Upon the Deep</td>\n",
       "      <td>Vernor Vinge</td>\n",
       "      <td></td>\n",
       "      <td>{\"/m/03lrw\": \"Hard science fiction\", \"/m/06n90...</td>\n",
       "      <td>The novel posits that space around the Milky ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    wid      fid                                      title           author  \\\n",
       "0   620  /m/0hhy                                Animal Farm    George Orwell   \n",
       "1   843  /m/0k36                         A Clockwork Orange  Anthony Burgess   \n",
       "2   986  /m/0ldx                                 The Plague     Albert Camus   \n",
       "3  1756  /m/0sww  An Enquiry Concerning Human Understanding       David Hume   \n",
       "4  2080  /m/0wkt                       A Fire Upon the Deep     Vernor Vinge   \n",
       "\n",
       "         date                                             genres  \\\n",
       "0  1945-08-17  {\"/m/016lj8\": \"Roman \\u00e0 clef\", \"/m/06nbt\":...   \n",
       "1        1962  {\"/m/06n90\": \"Science Fiction\", \"/m/0l67h\": \"N...   \n",
       "2        1947  {\"/m/02m4t\": \"Existentialism\", \"/m/02xlf\": \"Fi...   \n",
       "3                                                                  \n",
       "4              {\"/m/03lrw\": \"Hard science fiction\", \"/m/06n90...   \n",
       "\n",
       "                                             summary  \n",
       "0   Old Major, the old boar on the Manor Farm, ca...  \n",
       "1   Alex, a teenager living in near-future Englan...  \n",
       "2   The text of The Plague is divided into five p...  \n",
       "3   The argument of the Enquiry proceeds by a ser...  \n",
       "4   The novel posits that space around the Milky ...  "
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "names = ['wid', 'fid', 'title', 'author', 'date', 'genres', 'summary']\n",
    "\n",
    "books = pd.read_csv(\"data/booksummaries/booksummaries.txt\", sep=\"\\t\", header=None, names=names, keep_default_na=False)\n",
    "books.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We next filter the data so that only our target genre labels are included and we assign each text to just one of the genre labels.  It's possible that one text could be labelled with two of these labels (eg. Science Fiction and Fantasy) but we will just assign one of those here. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8954, 5)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_genres = [\"Children's literature\",\n",
    "                 'Science Fiction',\n",
    "                 'Novel',\n",
    "                 'Fantasy',\n",
    "                 'Mystery']\n",
    "\n",
    "# create a Series of empty strings the same length as the list of books\n",
    "genre = pd.Series(np.repeat(\"\", books.shape[0]))\n",
    "\n",
    "# look for each target genre and set the corresponding entries in the genre series to the genre label\n",
    "for g in target_genres:\n",
    "    genre[books['genres'].str.contains(g)] = g\n",
    "\n",
    "# add this to the book dataframe and then select only those rows that have a genre label\n",
    "# drop some useless columns\n",
    "books['genre'] = genre\n",
    "genre_books = books[genre!=''].drop(['genres', 'fid', 'wid'], axis=1)\n",
    "\n",
    "genre_books.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We inspect the numbers of each genre class. On the whole, each genre contains sufficient samples and look relatively balanced. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>author</th>\n",
       "      <th>date</th>\n",
       "      <th>summary</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>genre</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Children's literature</th>\n",
       "      <td>1092</td>\n",
       "      <td>1092</td>\n",
       "      <td>1092</td>\n",
       "      <td>1092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Fantasy</th>\n",
       "      <td>2311</td>\n",
       "      <td>2311</td>\n",
       "      <td>2311</td>\n",
       "      <td>2311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mystery</th>\n",
       "      <td>1396</td>\n",
       "      <td>1396</td>\n",
       "      <td>1396</td>\n",
       "      <td>1396</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Novel</th>\n",
       "      <td>2258</td>\n",
       "      <td>2258</td>\n",
       "      <td>2258</td>\n",
       "      <td>2258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Science Fiction</th>\n",
       "      <td>1897</td>\n",
       "      <td>1897</td>\n",
       "      <td>1897</td>\n",
       "      <td>1897</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       title  author  date  summary\n",
       "genre                                              \n",
       "Children's literature   1092    1092  1092     1092\n",
       "Fantasy                 2311    2311  2311     2311\n",
       "Mystery                 1396    1396  1396     1396\n",
       "Novel                   2258    2258  2258     2258\n",
       "Science Fiction         1897    1897  1897     1897"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check how many books we have in each genre category\n",
    "genre_books.groupby('genre').count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelling\n",
    "\n",
    "We use a Guassian Naive Bayes model to predict the book's genre. More specifically we use the Multi-Nomial variant. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import accuracy_score\n",
    "y = genre_books['genre']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We extract the class label (genre). We use the book summary as the determinant. There is also valuable information in the title, so we add that to the summary field. The author can also give a clue as to the book's genre, so we add that to the summary field too, as there are multiple books by the same author. We remove spaces from the author's name to create a single word feature: eg: \"George Orwell\" becomes \"GeorgeOrwell\". "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "#add the title and author to the summary\n",
    "X[\"summary\"] = X.loc[:, \"summary\"].str.cat(X.loc[:, \"title\"], sep=\" \").str.cat(X.loc[:, \"author\"].str.replace(\" \", \"\"), sep=\" \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We create a matrix of word counts using Python's CountVectorizer which is a special condensed matrix called a sparse matrix from the SciPy package. This is because most values contain zero and it is more memory efficient to store it in a special condensed format. There are also settings for minimum document frequency and maximum document frequency. We have specified that a word must be in atleast 8 documents. Because we have 5 genre classifications we specify we only use terms in less than 20% of the documents. \n",
    "\n",
    "From the shape of the matrix, we see that there are over 17,000 words used in the vector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type of word count vector:  <class 'scipy.sparse.csr.csr_matrix'>\n",
      "Vector shape (8954, 17510)\n"
     ]
    }
   ],
   "source": [
    "# produce a word count matrix\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "maximum_document_frequency = 0.2\n",
    "minimum_document_frequency = 8\n",
    "countV = CountVectorizer(max_df=maximum_document_frequency, min_df=minimum_document_frequency) \n",
    "# max: ignore words in 70% of docs; ignore words that exist in 1 doc only\n",
    "\n",
    "Xt = countV.fit_transform(X.summary)\n",
    "print(\"Type of word count vector: \", type(Xt))\n",
    "print(\"Vector shape\", Xt.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To inspect the word counts, we combine the word list with the sparse matrix to build up a sorted list. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_list = countV.get_feature_names()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create sorted word counts to inspect\n",
    "\n",
    "#count_list = X_train_counts.toarray().sum(axis=0) #too slow\n",
    "count_list = np.asarray(Xt.sum(axis=0))[0]\n",
    "\n",
    "count_list = zip(word_list, count_list)\n",
    "sorted_count_list = sorted(count_list, key=lambda x: x[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Least common words:\n",
      "[('12th', 8), ('130', 8), ('1857', 8), ('1870s', 8), ('1910', 8), ('1924', 8), ('1925', 8), ('1935', 8), ('1981', 8), ('46', 8), ('4th', 8), ('54', 8), ('666', 8), ('96', 8), ('abbreviated', 8), ('abject', 8), ('abnormal', 8), ('acceleration', 8), ('accountable', 8), ('admiring', 8)]\n",
      "\n",
      "Most common words:\n",
      "[('year', 2443), ('just', 2454), ('school', 2465), ('even', 2488), ('having', 2503), ('must', 2526), ('again', 2567), ('how', 2612), ('children', 2627), ('king', 2642), ('son', 2653), ('night', 2692), ('killed', 2722), ('earth', 2762), ('love', 2807), ('ship', 2930), ('were', 2974), ('war', 3151), ('city', 3167), ('house', 3932)]\n"
     ]
    }
   ],
   "source": [
    "print(\"Least common words:\")\n",
    "print(sorted_count_list[:20])\n",
    "print(\"\\nMost common words:\")\n",
    "print(sorted_count_list[-20:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The least common words contain numbers which wouldn't be very good predictors. The exception would be dates which may be of some historical significance in a novel or some futuristic date in a science fiction story. \n",
    "\n",
    "We see that there are only 215 such numbers that could be filtered out - out of 17000, not very significant. Every little bit helps, so we still use them as 'stop_words' in our Vectorizer. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Words containing numbers:  215\n"
     ]
    }
   ],
   "source": [
    "#exclude numbers, except for dates\n",
    "word_series = pd.Series(word_list)\n",
    "words_containing_numbers = wcn = word_series[word_series.str.match(r'\\d')]\n",
    "print(\"Words containing numbers: \", len(words_containing_numbers))\n",
    "date_words = wcn[wcn.str.match(r'([12][8901]\\d{2})|(\\d{1,2}(st|nd|rd|th))')] #1800, 1906, 21st, 2nd etc..\n",
    "stop_words = set(wcn).difference(set(date_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8954, 17431)"
      ]
     },
     "execution_count": 315,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "countV = CountVectorizer(stop_words=stop_words, max_df=maximum_document_frequency, min_df=minimum_document_frequency)\n",
    "Xt = countV.fit_transform(X.summary)\n",
    "Xt.shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We scale the word vector by the frequency that words appear in documents - more occurrences have greater weight. This is combined with number of times it appears in different documents - the more times it appears, the least affect it has. These concepts are called term frequency and inverse document frequency. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8954, 17431)"
      ]
     },
     "execution_count": 316,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# apply term frequency * inverse document frequency\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "#term frequency * inverse document frequency\n",
    "\n",
    "tfidf_transformer = TfidfTransformer()\n",
    "Xtt = tfidf_transformer.fit_transform(Xt)\n",
    "Xtt.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A cross validation score of only 63% is acheived. This is quite poor, so we try to leave out term frequency/inverse document frequency (tfidf) transformer. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gaussian Naive Bayes accuracy: 0.6318 +- 0.0288\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.model_selection import cross_val_score\n",
    "scores = cross_val_score(MultinomialNB(), Xtt, y, scoring='accuracy', cv=10)\n",
    "print('Gaussian Naive Bayes accuracy: %.4f +- %.4f\\n' % (scores.mean(), scores.std()))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A better result is acheived by leaving out the tf-idf transformer. This could be because we have already filtered out common/uncommon words in the word vectorizer using 'max_df' and 'min_df'. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy: 0.69 +- 0.03\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# try without Tfidf transformation\n",
    "NBmodel = MultinomialNB(alpha=1)\n",
    "scores = cross_val_score(NBmodel, Xt, y, scoring='accuracy', cv=10)\n",
    "print('Training accuracy: %.2f +- %.2f\\n' % (scores.mean(), scores.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)"
      ]
     },
     "execution_count": 320,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Final model evaluation\n",
    "from sklearn.metrics import confusion_matrix\n",
    "NBmodel = MultinomialNB()\n",
    "X_train, X_test, y_train, y_test = train_test_split(Xt, y, test_size=0.1, random_state=42)\n",
    "NBmodel.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We split the data into training and test.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training score: 0.82\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_train_pred = NBmodel.predict(X_train)\n",
    "\n",
    "train_score = accuracy_score(y_train, y_train_pred)\n",
    "train_matrix = confusion_matrix(y_train, y_train_pred)\n",
    "print(\"Training score: %.2f\\n\" % train_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test score: 0.68\n",
      "\n",
      "[[ 63  13  10  17   2]\n",
      " [ 21 149   9  21  23]\n",
      " [  7   5  95  17   7]\n",
      " [ 24   8  24 153  36]\n",
      " [  7  14   7  14 150]]\n",
      "\n",
      "\n",
      "Children's literature accuracy: 60.0%\n",
      "Fantasy accuracy: 66.8%\n",
      "Mystery accuracy: 72.5%\n",
      "Novel accuracy: 62.4%\n",
      "Science Fiction accuracy: 78.1%\n"
     ]
    }
   ],
   "source": [
    "y_test_pred = NBmodel.predict(X_test)\n",
    "\n",
    "test_score = accuracy_score(y_test, y_test_pred)\n",
    "test_matrix = confusion_matrix(y_test, y_test_pred)\n",
    "print(\"Test score: %.2f\\n\" % test_score)\n",
    "genres = NBmodel.classes_\n",
    "print(test_matrix)\n",
    "print(\"\\n\")\n",
    "for i, c in enumerate(test_matrix):\n",
    "    print(f\"{genres[i]} accuracy: {c[i]/c.sum()*100:.1f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The higher accuracy for the training data, suggests some overfitting of the model. Children's literature was the least accurate, most often mis-classified as either Fantasy or Novel. Fantasy was often classified as either Children's literature or Science Fiction. Mystery accuracy was relatively high, but often misclassified as novel. Novel's were most mis-classified as fantasy. The highest accuracy was science fiction, which was often mis-classified as either novel or fantasy. \n",
    "\n",
    "One observation is that classification of genres can be arbitrary. For example the distinction between Science Fiction or Fantasy/Science fantasy is blurry. Likewise for Children's literature and Fantasy. The most general category of novel could be classified into any other category. This is reflected in a low accuracy. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This model is based on a white list approach (as compared to a black list approach of the previous model) and is based on the idea that nouns will be better predictors as they will be more subject specific. We can also look at other parts of speech as predictors such as verbs and adjectives.\n",
    "\n",
    "The multinomial naive based model is used again, but the input data will be transformed to include the relevant parts of speech. To help with this, Python's Natural Language Toolkit (NLTK) package is used to identify parts of speech (POS) for each word. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from scipy import sparse\n",
    "#nltk.download(\"punkt\")\n",
    "#nltk.download('averaged_perceptron_tagger')\n",
    "#nltk.download('tagsets')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A new word vector is created with no filtering.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [],
   "source": [
    "#countV = CountVectorizer(stop_words=stop_words, max_df=0.1, min_df=8)\n",
    "countV = CountVectorizer()\n",
    "multinomialNB = MultinomialNB()\n",
    "Xt = countV.fit_transform(X.summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The words used in the vector are retrieved and converted to a Pandas Series. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_list = countV.get_feature_names()  \n",
    "word_series = pd.Series(word_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We create a new series, identifying the parts of speech of each word. The new series will contain a 2 or 3 letter key to identify a part of speech, for example 'NN' for Nouns, 'JJ' for adjectives etc. 3 letter keys usually denote a sub-category, for example NNP is a proper singular noun. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pos(x):\n",
    "    return nltk.pos_tag([x])[0][1]\n",
    "position_of_speech = word_series.transform(pos)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A list of verbs, nouns and adjectives are then created.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [],
   "source": [
    "verbs = word_series[position_of_speech.str.match(r'VB[A-Z]{0,2}')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [],
   "source": [
    "nouns = word_series[position_of_speech.str.match(r'NN[A-Z]{0,2}')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [],
   "source": [
    "adjectives = word_series[position_of_speech.str.match(r'JJ[A-Z]{0,2}')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The word vector (countV) has an attribute vocabulary_, which is a dictionary of words (as keys) with their column indexes in the sparse matrix as values. We use these to create a list of sparse matrix column indexes for nouns, verbs and adjectives. These will be used to create new matrices, depending on the part of speech we want to use in our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [],
   "source": [
    "noun_column_indexes = [countV.vocabulary_.get(key) for key in nouns]\n",
    "verb_column_indexes = [countV.vocabulary_.get(key) for key in verbs]\n",
    "adjective_column_indexes = [countV.vocabulary_.get(key) for key in adjectives]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We create a new noun matrix and carry out a cross validation test for a multinomial naive bayes model.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for Nouns only: 0.69 +- 0.03\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame(Xt.toarray())\n",
    "noun_matrix = sparse.csr_matrix(df[noun_column_indexes])\n",
    "scores = cross_val_score(multinomialNB, noun_matrix, y, scoring='accuracy', cv=10)\n",
    "print('Accuracy for Nouns only: %.2f +- %.2f\\n' % (scores.mean(), scores.std()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We do the same thing again, but for a word matrix for nouns and verbs combined.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nouns + Verbs: 0.70 +- 0.02\n",
      "\n"
     ]
    }
   ],
   "source": [
    "noun_verb_matrix = sparse.csr_matrix(df[noun_column_indexes + verb_column_indexes])\n",
    "scores = cross_val_score(multinomialNB, noun_verb_matrix, y, scoring='accuracy', cv=10)\n",
    "print('Nouns + Verbs: %.2f +- %.2f\\n' % (scores.mean(), scores.std()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is a slight improvement. Finally we test for nouns, verbs and adjectives combined in the model.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nouns + verbs + adjectives: 0.70 +- 0.03\n",
      "\n"
     ]
    }
   ],
   "source": [
    "noun_verb_adj_matrix = sparse.csr_matrix(df[noun_column_indexes + verb_column_indexes + adjective_column_indexes])\n",
    "scores = cross_val_score(multinomialNB, noun_verb_adj_matrix, y, scoring='accuracy', cv=10)\n",
    "print('Nouns + verbs + adjectives: %.2f +- %.2f\\n' % (scores.mean(), scores.std()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the accuracy figures, adjectives didn't contribute anything to the model, execpt introduce slightly wider variation. In the interests of parsimony, we fit the noun + verb matrix..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)"
      ]
     },
     "execution_count": 356,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train2, X_test2, y_train2, y_test2 = train_test_split(noun_verb_matrix, y, test_size=0.1, random_state=42)\n",
    "multinomialNB.fit(X_train2, y_train2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training score: 0.91\n"
     ]
    }
   ],
   "source": [
    "y_train_pred2 = multinomialNB.predict(X_train2)\n",
    "\n",
    "train_score = accuracy_score(y_train2, y_train_pred2)\n",
    "#train_matrix = confusion_matrix(y_train2, y_train_pred2)\n",
    "print(f\"Training score: {train_score:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing score 0.70\n"
     ]
    }
   ],
   "source": [
    "y_test_pred2 = multinomialNB.predict(X_test2)\n",
    "\n",
    "test_score = accuracy_score(y_test2, y_test_pred2)\n",
    "#train_matrix = confusion_matrix(y_train2, y_train_pred2)\n",
    "print(f\"Testing score {test_score:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When comparing accuracy scores for training agaist testing, the large discrepency suggests overfitting in the model. There is a slight improvement in the testing accuracy (around 2%) but at the expense of significantly larger predictor matrix (over 84000 words compared to 17000 for model 1). There was also significantly more pre-processing for model 2. Overall, model 1 would be more preferrable. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "84339"
      ]
     },
     "execution_count": 270,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train2.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17590"
      ]
     },
     "execution_count": 271,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape[1]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
